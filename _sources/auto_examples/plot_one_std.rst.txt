
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/plot_one_std.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_examples_plot_one_std.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_plot_one_std.py:


===============================================================
Using one-standard-deviation rule in hyperparameters selection
===============================================================

One-standard-deviation rule is a technique to promote model robustness when
cross validation results are noisy. The hyperparameter is chosen to
be equal to the maximum value that yields:
     CV = minimum CV + 1 * std(CV at minimum).

One-standard-deviation rule is available in both GridSearchCV and LineSearchCV
under sparselm.model_selection.

.. GENERATED FROM PYTHON SOURCE LINES 14-109



.. rst-class:: sphx-glr-horizontal


    *

      .. image-sg:: /auto_examples/images/sphx_glr_plot_one_std_001.png
         :alt: plot one std
         :srcset: /auto_examples/images/sphx_glr_plot_one_std_001.png
         :class: sphx-glr-multi-img

    *

      .. image-sg:: /auto_examples/images/sphx_glr_plot_one_std_002.png
         :alt: plot one std
         :srcset: /auto_examples/images/sphx_glr_plot_one_std_002.png
         :class: sphx-glr-multi-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Lasso with 1-std performance metrics:
        train r2: 0.975
        test r2: 0.954
        train rmse: 33.629
        test rmse: 41.532
        sparsity: 41
    Lasso performance metrics:
        train r2: 0.969
        test r2: 0.952
        train rmse: 37.434
        test rmse: 42.415
        sparsity: 25






|

.. code-block:: default


    import matplotlib.pyplot as plt
    import numpy as np
    from sklearn.datasets import make_regression
    from sklearn.linear_model import Lasso
    from sklearn.metrics import mean_squared_error, r2_score
    from sklearn.model_selection import KFold, train_test_split

    from sparselm.model_selection import GridSearchCV

    X, y, coef = make_regression(
        n_samples=200,
        n_features=100,
        n_informative=10,
        noise=40.0,
        bias=-15.0,
        coef=True,
        random_state=0,
    )

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.25, random_state=0
    )

    # create estimators
    lasso = Lasso(fit_intercept=True)

    # create cv search objects for each estimator
    cv5 = KFold(n_splits=5, shuffle=True, random_state=0)
    params = {"alpha": np.logspace(-1, 1, 10)}

    lasso_cv_std = GridSearchCV(
        lasso, params, opt_selection_method="one_std_score", cv=cv5, n_jobs=-1
    )
    lasso_cv_opt = GridSearchCV(
        lasso, params, opt_selection_method="max_score", cv=cv5, n_jobs=-1
    )

    # fit models on training data
    lasso_cv_std.fit(X_train, y_train)
    lasso_cv_opt.fit(X_train, y_train)

    # calculate model performance on test and train data
    lasso_std_train = {
        "r2": r2_score(y_train, lasso_cv_std.predict(X_train)),
        "rmse": np.sqrt(mean_squared_error(y_train, lasso_cv_std.predict(X_train))),
    }

    lasso_std_test = {
        "r2": r2_score(y_test, lasso_cv_std.predict(X_test)),
        "rmse": np.sqrt(mean_squared_error(y_test, lasso_cv_std.predict(X_test))),
    }

    print("Lasso with 1-std performance metrics:")
    print(f"    train r2: {lasso_std_train['r2']:.3f}")
    print(f"    test r2: {lasso_std_test['r2']:.3f}")
    print(f"    train rmse: {lasso_std_train['rmse']:.3f}")
    print(f"    test rmse: {lasso_std_test['rmse']:.3f}")
    print(f"    sparsity: {sum(abs(lasso_cv_std.best_estimator_.coef_) > 1E-8)}")

    lasso_opt_train = {
        "r2": r2_score(y_train, lasso_cv_opt.predict(X_train)),
        "rmse": np.sqrt(mean_squared_error(y_train, lasso_cv_opt.predict(X_train))),
    }

    lasso_opt_test = {
        "r2": r2_score(y_test, lasso_cv_opt.predict(X_test)),
        "rmse": np.sqrt(mean_squared_error(y_test, lasso_cv_opt.predict(X_test))),
    }

    print("Lasso performance metrics:")
    print(f"    train r2: {lasso_opt_train['r2']:.3f}")
    print(f"    test r2: {lasso_opt_test['r2']:.3f}")
    print(f"    train rmse: {lasso_opt_train['rmse']:.3f}")
    print(f"    test rmse: {lasso_opt_test['rmse']:.3f}")
    print(f"    sparsity: {sum(abs(lasso_cv_opt.best_estimator_.coef_) > 1E-8)}")

    # plot predicted values
    fig, ax = plt.subplots()
    ax.plot(y_test, lasso_cv_std.predict(X_test), "o", label="One std", alpha=0.5)
    ax.plot(y_test, lasso_cv_opt.predict(X_test), "o", label="Max score", alpha=0.5)
    ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], "k--")
    ax.set_xlabel("true values")
    ax.set_ylabel("predicted values")
    ax.legend()
    fig.show()

    # plot model coefficients
    fig, ax = plt.subplots()
    ax.plot(coef, "o", label="True coefficients")
    ax.plot(lasso_cv_std.best_estimator_.coef_, "o", label="One std", alpha=0.5)
    ax.plot(lasso_cv_opt.best_estimator_.coef_, "o", label="Max score", alpha=0.5)
    ax.set_xlabel("covariate index")
    ax.set_ylabel("coefficient value")
    fig.show()


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  0.594 seconds)


.. _sphx_glr_download_auto_examples_plot_one_std.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example




    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_one_std.py <plot_one_std.py>`

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_one_std.ipynb <plot_one_std.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
